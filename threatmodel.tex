
\section{Threat Model}

In FOKS, we consider a threat model similar to that of the Keybase~\cite{keybase},
SEAMLess~\cite{chase2019seemless} or CONIKs~\cite{melara2015coniks} systems.
The high level north star is end-to-end secrecy and integrity. Only the clients
at the edges of the system should be able to decrypt important data, and only
those clients can make authorized changes to the data. Of course, multiple
devices per user and mutable groups complicate the picture.

We assume that clients are trustworthy, and behave properly. If this assumption
is violated, say, if a client is compromised by a rootkit, then we cannot
offer any guarantees. 

Users might sometimes lose their devices. In an ideal world, hardware protections
would prevent whoever recovered the device from accessing the device's private
key material. In the case of hardware keys (like YubiKeys), or backup-keys
written on paper, the user has less protection during comrpomise. Regardless,
once the user revokes the lost device, keys should rotate so that data is secure
going forward (this property is known post-compromise security). In some cases,
past data might be safe from the attacker (this property is known as forward-secrecy).
but the specifics depend on the trustworthiness of the server (see below). Similarly, revoked
keys on lost devices lose their signing power, and other devices will not accept
their signatures going forward.

The threat model is here is similar but not exactly the same as Signal's and
WhatsApp's, because our applications feature persistent (rather than ephemeral)
data. If a new user joins an existing group, or if a user adds a new device,
they should be able to access old data, which might be required to reassemble the
shared resource. For instance, when Alice adds Bob to a git project, Bob
should see all past commits in the commit history, otherwise the
application will break. Thus, we can't guarantee foward-secrecy, since
lack of forward secrecy is needed for the application to function properly.

In FOKS, clients pick their servers. They might select for servers
that are generally aligned with. They can run their own servers, or pick 
from third party hosting providers. Users should assume that servers
are generally trustworthy, but might suffer comrpomises from time to time.
For instance, servers might be running on cloud infrastructure, and the underlying
storage, network, or computation might be compromised. Insiders or state actors
might have privileged access to the underlying infrascture. 

If servers behave honestly, the FOKS system works securely as expected.  If
servers behave maliciously, they can deny access to data through a variety of
mechanisms: they can go offline, they can withoold data, or they can subtly
current server-resident data to confuse clients. In this last case, the system's
security design should prevent the clients from leaking secrets or accepting
unauthorized changes to data. But as in the other more obvious cases, the
clients will lose access to their data.

When servers are behaving honestly, they can provide clients with
forward-secrecy. That is, if honest servers throw away data encrypted with old
keys, an attackets with access to private keys cannot rcannot ecover past data.
This property is an improvement over that offered by the Keybase system, which
assumed the worst in the case of a comrpomise. If we assume on the other hand
that an attacker who steals a private key operates in cohoots with the server,
then we cannot offer any guarantees about forward secrecy.

Servers do not trust each other. If one server becomes corrupted, it has no
bearing on the other servers in the system. In other words, we assume attackers
can stand up their own servers, since anyone in the system can do so.

